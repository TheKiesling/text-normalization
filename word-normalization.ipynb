{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04d6f778",
   "metadata": {},
   "source": [
    "# Word Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29053ab",
   "metadata": {},
   "source": [
    "### José Pablo Kiesling Lange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ec017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf80513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"data/escher_comments.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e16c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpus_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    corpus = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e84622",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [line.strip() for line in corpus if line.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae86c91",
   "metadata": {},
   "source": [
    "## Estandarización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7dd89a",
   "metadata": {},
   "source": [
    "Para ver la efectivdad de la estandarización, se mostrará las 10 palabras más frecuentes del corpus antes y después de la estandarización. El objetivo es ver si hay modificación en la cantidad de dichas palabras o si una nueva palabra aparece con frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3c16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words(corpus, n=10):\n",
    "    words = [word for line in corpus for word in line.split()]\n",
    "    most_common = Counter(words).most_common(n)\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f920a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('que', 45),\n",
       " ('de', 39),\n",
       " ('la', 32),\n",
       " ('un', 27),\n",
       " ('una', 26),\n",
       " ('el', 17),\n",
       " ('en', 16),\n",
       " ('esfera', 15),\n",
       " ('reflejo', 15),\n",
       " ('y', 14)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words = get_most_common_words(corpus, n=10)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540c7b7",
   "metadata": {},
   "source": [
    "#### Case Folding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0e6f8",
   "metadata": {},
   "source": [
    "Se hace una función que dado un corpus revisa si posee la misma palabra en mayúscula y minúscula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bbce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_lower_words(corpus):\n",
    "    words = set(word for line in corpus for word in line.split())\n",
    "    upper_lower_words = set()\n",
    "    for word in words:\n",
    "        if word.lower() in words and word.upper() in words:\n",
    "            upper_lower_words.add(word)\n",
    "    return upper_lower_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e89453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'a'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_lower_words = get_upper_lower_words(corpus)\n",
    "upper_lower_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69df04e",
   "metadata": {},
   "source": [
    "Dado que sí hay por lo menos una palabra que aparece en ambas formas, se procede a hacer un case folding (pasar todas las palabras a minúscula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18cce89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(corpus):\n",
    "    return [line.lower() for line in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa0588d",
   "metadata": {},
   "source": [
    "#### Remove Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8259178",
   "metadata": {},
   "source": [
    "Dado que en las instrucciones para generar el corpus se pidió mínimo 2 oraciones, se asume que mínimo una de las oraciones tiene puntuación. Por lo tanto, se procede a eliminar la puntuación del corpus.\n",
    "\n",
    "Esto se hace para evitar que palabras como `la,` o `la.` se cuenten como palabras diferentes a `la`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84702dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(corpus):\n",
    "    return [re.sub(r'[^\\w\\s]', '', line) for line in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77dcac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarizate(corpus):\n",
    "    corpus = case_folding(corpus)\n",
    "    corpus = remove_punctuation(corpus)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff629776",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = standarizate(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc1db96",
   "metadata": {},
   "source": [
    "### Corpus ya estandarizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5800cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('que', 45),\n",
       " ('de', 39),\n",
       " ('la', 34),\n",
       " ('un', 30),\n",
       " ('una', 28),\n",
       " ('esfera', 18),\n",
       " ('en', 18),\n",
       " ('el', 17),\n",
       " ('reflejo', 16),\n",
       " ('se', 15)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words = get_most_common_words(corpus, n=10)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4786f53",
   "metadata": {},
   "source": [
    "Como se puede apreciar:\n",
    "- la palabra `la` se incrementó en `2`ocurrencias\n",
    "- la palabra `un` se incrementó en `3` ocurrencias\n",
    "- la palabra `una` se incrementó en `3`ocurrencias\n",
    "- la palabra `esfera` se incrementó en `3` ocurrencias y subió al `6to` lugar\n",
    "- la palabra `en` se incrementó en `2` ocurrencias y subió al `7mo` lugar\n",
    "- la palabra `reflejo` se incrementó en `1` ocurrencia\n",
    "- la palabra `se` **ingresó** al top 10\n",
    "\n",
    "Por lo tanto, la estandarización ha tenido un efecto positivo en la, ya que ha incrementado la cantidad de ocurrencias de palabras comunes y ha eliminado las variaciones causadas por puntuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa525a",
   "metadata": {},
   "source": [
    "Algo a recalcar es la ausencia de la estandarización de palabras con o sin tilde. Esto es porque se entrenará el modelo `BPE` en español."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e3c75",
   "metadata": {},
   "source": [
    "## BPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a6b08",
   "metadata": {},
   "source": [
    "La implementación se hará en base a la implementación de `LangformersBlog`\n",
    "\n",
    "https://blog.langformers.com/bpe-tokenizer-explained/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad22c926",
   "metadata": {},
   "source": [
    "En la instanciación del `BpeTrainer` se especifica el tamaño del vocabulario y los tokens especiales. Para definir el tamaño del vocabulario, se debe considerar el tamaño del corpus y la cantidad de palabras que se espera que aparezcan en el corpus. Por lo tanto, se hacen métodos para calcular el tamaño del vocabulario y la cantidad de palabras que se espera que aparezcan en el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be419549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size(corpus):\n",
    "    return len(set(word for line in corpus for word in line.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a860d0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario estimado por tokens únicos: 229\n"
     ]
    }
   ],
   "source": [
    "vocab_size = get_vocab_size(corpus)\n",
    "print(f\"Vocabulario estimado por tokens únicos: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87f443",
   "metadata": {},
   "source": [
    "Dado que el corpus es pequeño, se define un tamaño de vocabulario de `300` y los tokens especiales son `[PAD]` y `[UNK]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "952f6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77714657",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=300,\n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d98402",
   "metadata": {},
   "source": [
    "El token `[PAD]` se utiliza para rellenar secuencias de longitud variable, mientras que el token `[UNK]` se utiliza para representar palabras desconocidas o fuera del vocabulario.\n",
    "\n",
    "Ejemplo:\n",
    "Si el corpus contiene las palabras `hola`, `mundo`, y `adiós`, el vocabulario podría ser:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"[PAD]\": 0,\n",
    "    \"[UNK]\": 1,\n",
    "    \"hola\": 2,\n",
    "    \"mundo\": 3,\n",
    "    \"adiós\": 4\n",
    "}\n",
    "```\n",
    "\n",
    "Entonces si viniera el texto `hello mundo adiós` y otro texto `hola mundo`, el tokenizador lo convertiría a\n",
    "1. [1, 3, 4] (donde `1` es el token `[UNK]` para `hello`)\n",
    "2. [2, 3, 0] (donde `0` es el token `[PAD]` para la secuencia de longitud variable)\n",
    "\n",
    "Es por ello que el uso de ambos tokens es importante para manejar secuencias de longitud variable y palabras desconocidas. En el caso de `PAD` es útil para rellenar secuencias más cortas, mientras que `UNK` es esencial para manejar palabras que no están en el vocabulario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69c3fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train_from_iterator(corpus, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8443edf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'todo ': 205, 'ci': 59, 'em': 216, 'c': 5, 'j': 12, 'ás ': 116, 's ': 90, 'los ': 290, 'iz': 219, 'si': 85, 'cur': 282, 'sí m': 151, 'ser ': 253, 'ver ': 204, 'dentr': 286, 'b': 4, 'él ': 233, 'al': 77, 'pción ': 294, 'ser': 91, 'a': 3, 'oca ': 225, 'endo ': 117, 'et': 177, 'habitación ': 152, 're': 40, 'sostiene una esfera ': 256, 'ilu': 288, 'é': 28, 'alrede': 198, 'en la ': 163, 'ent': 50, 'al ': 113, 'iendo ': 126, 'del ': 114, 'una esfera reflect': 199, 'str': 297, 'an': 55, 'veo ': 120, 'present': 166, 'esfera ': 73, 'habita': 135, 'que es ': 191, 'lo que ': 133, 'lu': 156, 'estra ': 266, 'co': 106, 'entorno ': 271, 'ver': 130, 'muebles ': 254, 'su ': 93, 'mano ': 171, 'n ': 38, 'lo ': 84, 'is': 83, 'tom': 299, 'bles ': 212, 'va ': 96, 'di': 154, 'más ': 139, 'da la ': 215, '[PAD]': 0, 'ct': 124, 'ma ': 182, 'to': 141, 'se ve ': 121, 'de ': 43, 'ti': 65, 'en': 36, 'so': 140, 'está ': 149, 'com': 125, 'g': 9, 'jo ': 220, 'entr': 240, 'refleja ': 162, 'i': 11, 'v': 23, 'lo': 289, 'ú': 32, 'una esfera ': 86, 'ta': 70, ' lo que ': 273, 'le': 46, 'ene ': 102, 'm': 14, 'imient': 202, 'pl': 293, 'istal ': 250, 'ca ': 214, 'perspectiva ': 272, 'im': 107, 'reflexión ': 193, 'reflect': 192, 'ación ': 137, 'bi': 87, 'as': 274, 'o': 16, 'pi': 226, 'dad': 285, 'espe': 236, 'sosten': 145, 'su': 68, 'o de ': 72, 'f': 8, 'pro': 165, 'ombr': 78, 'tiva ': 164, 'el ': 54, 'pin': 185, 'ad': 112, 'una mano ': 194, 'no ': 108, 'én ': 232, 'imag': 201, 'parece ': 208, 'ndos': 292, 'obser': 111, 'ob': 88, 'reflej': 56, 'mente ': 207, 'ión ': 179, 'hombre ': 82, 'de la ': 143, 'ar ': 167, 'dos': 283, 'propi': 261, 'pec': 148, 'un hombre que ': 147, 'er': 39, 'un hombre ': 92, 'bita': 134, 'con ': 150, 'sosteniendo ': 172, 'de cristal ': 270, 'como ': 170, 'n': 15, 'q': 18, 'qu': 41, 'es ': 63, 'co ': 279, 'na ': 51, 'au': 123, 'aliz': 249, 'y ': 71, 'l ': 44, 'reflejo ': 103, 've': 95, 'spec': 229, 'sostiene ': 119, 'a ': 34, 'aut': 169, 'cr': 213, 'in': 100, 'es': 37, 'les ': 180, 'ment': 183, 'tra': 247, 'sen': 296, 'ción ': 76, 'perso': 251, 'r ': 295, '[UNK]': 1, 'man': 138, 'ó': 31, 'tr': 75, 'có': 278, 'ebles ': 217, ' m': 122, 'or ': 132, 'ient': 178, 'a que ': 235, 'estr': 188, 'tal ': 246, 't': 21, 'en un ': 243, 'la esfera ': 239, 'cen': 280, 'bu': 276, 'do ': 61, 'el': 287, 'perspec': 252, 'ombre ': 81, 'á ': 131, 'en ': 58, 'en se ve ': 244, 'e': 7, 'ismo ': 146, 'que mu': 237, 'la ': 47, 'sí mismo ': 173, 'po': 227, 'p': 17, 'ante ': 136, 'en el ': 196, 'x': 24, 'mo ': 127, 'pue': 259, 'parec': 186, 'nos': 291, 'alreded': 209, 'otr': 224, 'ant': 118, 'sí': 128, 'á': 27, 'cu': 176, 'es un ': 245, 'li': 155, 'dis': 284, 'est': 97, 'mbi': 222, 'l': 13, 'ten': 115, 'ando ': 161, 'fer': 67, 'esfer': 69, 'ur': 129, 'representación ': 267, 'or': 62, 'z': 26, 'r': 19, 'reflejo de ': 144, 'mos ': 184, 'refle': 49, 'de': 98, 'libros ': 206, 'ón ': 60, 'pe': 94, 'for': 218, 'una ': 53, 'entor': 241, 'su reflejo ': 200, 'autor ': 263, 'ces ': 281, 'u': 22, 'sos': 80, 'ación de ': 258, 'tur': 230, 'observ': 168, 'observa ': 203, 'una esfera reflectante ': 210, 'ar': 105, 'mu': 101, 'voca ': 231, 'a la ': 109, 'esent': 159, 'e ': 33, 'xión ': 187, 'at': 174, 'y': 25, 'h': 10, 'ha': 99, 'ado ': 211, 'ta ': 142, 'sosteniendo una esfera ': 264, 'de cr': 238, 'se ': 74, 'sación de ': 298, 'arec': 175, 'br': 64, 'om': 57, 'alg': 248, 'el reflejo de ': 195, 'pintur': 265, 'ce': 277, 'sentimient': 260, 'se v': 110, 'se': 228, 'rec': 160, 'jet': 221, 'que muestra ': 269, 'me ': 181, 'o ': 35, 'on': 223, 'd': 6, ' ': 2, 'una habitación ': 242, 'con': 255, 'represent': 190, 'í': 29, 'observar ': 262, 'que ': 42, 'tiene ': 104, 'sent': 158, 's': 20, 'forma ': 268, 'pu': 157, 'bros ': 197, 'os': 45, 'un ': 52, 'os ': 66, 'rede': 189, 'ún': 234, 'bo': 275, 'ñ': 30, 'fle': 48, 'veo a ': 257, 'pr': 79, 'ag': 153, 'per': 89}\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary:\", tokenizer.get_vocab())\n",
    "tokenizer.save(\"tiny_tokenizer.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
